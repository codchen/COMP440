\documentclass[11pt]{article}
\usepackage[left=2cm,top=2cm,right=2cm,bottom=2cm]{geometry}
\usepackage{graphicx}
\usepackage{setspace}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage[]{algorithm2e}
\usepackage[noend]{algpseudocode}
\usepackage{float}
\title{COMP 440 Homework 1}
\author{Tony Chen(xc12) and Adam Wang(sw33)}
\date{August 2016}
\begin{document}
\begin{onehalfspace}
    \maketitle
    \newpage{}
    \section{Modeling sentence segmentation as search}
    \begin{itemize}
        \item
        Suppose the sentence length is $L$, we define the state space model as following:
        \begin{itemize}
            \item
            $S = s_0\cup s_1\cup s_2\cup ... \cup s_L$, where, for $i = 0, 1, 2, ... L$, $s_i$ represents the state that exactly $i$ first characters have been segmented into words.
            \item
            $Action$ is defined as: for every word $w$ in $D$ that is a prefix of the substring that starts at the $i$-th character in the sentence, $a_{s_i,w}$ is the action to jump to state $s_{s_i+len(w)}$.
            \item
            $Successor(s_i, a_{i,w}) = s_{i+len(w)}$
            \item
            $Cost(s_i, a_{i,w}) = 1$
            \item
            $s_{start} = s_0$
            \item
            $isGoal(s_i) = (s_i == s_L)$
        \end{itemize}
        \item
        *Since the paths of unweighted graph of states are directed and never going "backward", there's no cycle in the graph.
        \begin{itemize}
            \item
            Yes. BFS will be able to traverse the graph layer by layer from $s_0$ and once it reaches $s_L$, the current distance (number of layers traversed) is the minimum cost path. Time complexity will be $O(b^s)$ where $b$ is the average number of neighbours and $s$ is the number of layers from $s_0$ to $s_L$.
            \item
            No. DFS will not guarantee the distance we have when we find $s_L$ to be the minimum cost path.
            \item
            Yes. UFS will be able to find a least cost path from $s_0$ to $s_L$ in $O(L)$.
            \item
            Yes. A* with a consistent heuristic will be able to find a least cost path from $s_0$ to $s_L$ in $O(L)$.
            \item
            Yes. Bellman-Ford will be able to find a least cost path from $s_0$ to $s_L$ in $O(L^2|A|)$, where $|A|$ is the number of edges.
        \end{itemize}
        \item
            Modify $Cost$ function so that $Cost(s_i, a_{i,w}) = len(w) - 1$. \\
            BFS won't work now since it only works on unweighted graph. UFS, A*, and Bellman-Ford will still work since they all can generalize on weighted graph.
        \item
            Modify $S$ so that for a state $s_{i,last}$ where $i > 0$, exactly $i$ first characters have been segmented and the last segmented word is $last$. \\
            Modify $Cost$ function so that $Cost(s_0, a_{0,w}) = 0$ and $Cost(s_{i,last}, a_{i,w}) = fluency(last, w)$.
    \end{itemize}
    \newpage{}
    \section{Searchable Maps}
    \begin{itemize}
        \item
        We define the cost as the time required to travel from $s$ to $t$. Since we need a heuristic that never overestimates the cost, we define it as the lowest possible cost, which is obtained by a traveling along a straight line from $s$ to $t$ at the highest possible speed: \\
        \begin{eqnarray*}
            h(s, t) = \frac{G(s, t)}{S_H}
        \end{eqnarray*}
        \item
        The heuristic is defined as following:
        \begin{eqnarray*}
            h(s, t) = |T(s, L) - T(L, t)|
        \end{eqnarray*}
        Proof: Suppose there is a neighbour node $n$, then we need to prove that $h(s, t) \leq Cost(s, n) + h(n, t)$. Consider all sign combinations of $T(s, L) - T(L, t)$ and $T(n, L) - T(L, t)$ with the fact that $T(s, L) \leq Cost(s, n) + T(n, L)$ (triangular inequality), we see that $h(s, t) \leq Cost(s, n) + h(n, t)$ holds at all time.
        \item
        Suppose the goal node is $t$, it is trivial that $h(t) = h_1(t) = h_2(t) = 0$.
        Consider any pair of node $n$ and $m$ where there is an action to get $m$ from $n$. Suppose $h_1(n) \geq h_2(n)$, then $h(n) = h_1(n)$ and there are two possibilities: first, $h_1(m) \geq h_2(m)$, which makes $h(m) = h_1(m)$ and obviously makes $h$ consistent on $n$ and $m$ ($h$ is exactly $h_1$); second, $h_1(m) < h_2(m)$, then since $h(n) = h_1(n) \leq Cost(n,m) + h_1(m) < Cost(n,m) + h_2(m)$, $h$ is also consistent on $n$ and $m$. So $h$ will always be consistent in this case\\
        Since $h_1$ and $h_2$ are symmetric, the above conclusion will also hold for $h_1(n) < h_2(n)$. So $h$ is always consistent.
        \item According to part c, the basic idea is to take the max of all heuristics:
        \begin{eqnarray*}
            h(s, t) = max(|T(s, L_1) - T(L_1, t)|, |T(s, L_2) - T(L_2, t)|, ... , |T(s, L_K) - T(L_K, t)|, \frac{G(s, t)}{S_H})
        \end{eqnarray*}
        \item
        For adding edges, $h$ will NOT remain consistent. Imagine the new edge draws a straight line from $s$ to $t$, then as long as the original path estimate of $h$ is not a straight line on its own, $h$ will overestimate, which makes it not only inconsistent but also not admissible. \\
        For removing edges, $h$ will still remain consistent. Since for any edge remains in the graph, none of the three parts in the inequality $h(m) \leq Cost(m, n) + h(n)$ will change. So $h$ will remain consistent.
    \end{itemize}
    \newpage{}
    \section{Package Delivery as Search}
    \begin{itemize}
    	\item
    	2a
	\begin{itemize}
		\item
		States: Location $(x, y)$ of the truck, a vector $S$ of length $numPackages$ where $S[i]
		             \in \{-1, 0, 1\}$ where -1 denotes package $i$ has not been picked up, $0$ denotes
		             package i has been picked up and not dropped off and $1$ denotes package i 
		             has been dropped off.
		\item
		Actions: North, East, West, South, Pickup and Dropoff
		\item
		Successor: If action is North, East, West or South, update location respectively.
		                   If action is Pickup, in the vector in state, change from -1 to 0 for the 
		                   corresponding package.
		                   If action is Drop-off, in the vector in state, change from 0 to 1 for the
		                   corresponding package.
		\item
		Cost: If action is North, East, West or South, cost is 1 plus number of packages carried
			 If action is Pickup or Dropoff, cost is 0.
		
		 \item
		 Initial state: Truck's starting location and a vector of -1 of length number of packages to 
		                     pickup.
		\item
		Goal test: If truck's location is the starting location and if the vector in the state are all 1s.
		Number of states: $m*n*3^k$.
	\end{itemize}
	\item
	2c. Number of states explored: 56 
	\item
	2d. Number of states explored: 34  
	\item
	2e. Number of states explored: 56
   \end{itemize}
    \newpage{}
    \section{Designing Search Algorithms: Protein Folding}
    Literature referenced\cite{protein}
    \begin{itemize}
    \item
    Suppose the input sequence $s$ has L acids.
    $S$ contains $s_{directions}$ which is a length-$L$ ordered list, of which each element $l_i$ is the direction from the $i$-th acid to the $i+1$-th acid. Each direction is one of $N(0,1)$, $S(0,-1)$, $W(-1,0)$, or $E(1,0)$. There is a constraint that there must exist no pair $(i, j)$ such that $\sum_{k=i}^j l_k = (0,0)$ (self-avoiding). \\ \\
    $s_0$ is a list of $L$ randomly generated directions that satisfies the self-avoiding constriant.\\ \\
    $s_{Goal}$ is achieved when $Cost(s)$ becomes smaller than a fixed threshold. \\ \\
    $A$ contains $a_{i, dir}$, which changes the direction of the $i$-th acid to $dir$ if such change will not break the self-avoiding constraint. \\ \\
    $Succ(s_{directions}, a_{i, dir}) = s_{directions'}$, \\where $directions'[i] = dir$ and $directions'[j] = directions[j],\forall j \ne i$ \\ \\
    $Cost(s_{directions}, a_{i, dir})$ is the difference between sum of all H-H pairs of acid locations generated by $directions$ and that of $directions'$.
    \item
    Local search algorithm. \\
    Because we only care about the final conformation of the protein, not how we change the sequence topologically to achieve that. \\
    Also because the search space is too large to run algorithms that search for global optimum. 
    \item
    \newcommand\tab[1][1cm]{\hspace*{#1}}
    Function ProteinFolding \\
    Input: protein sequence in its string form \\
    \tab $Population <- $ 200 randomly generated conformation \\
    \tab Iterate for 200 times: \\
    \tab\tab sort $Population$ based on their costs in ascending order\\
    \tab\tab retain the first half of $Population$\\
    \tab\tab replace the second half of $Population$ with children of randomly chosen parents by a \tab\tab2-point crossover with rate $0.2$-$0.8$.\\
    \tab\tab randomly mutate each new-born conformation at chance $0.4$, by randomly altering one \tab\tab of its direction.\\
    \tab return the conformation with the lowest cost\\
    Time Complexity: $O(l*m*n(log(n))$, where $l$ is the length of the input sequence, $m$ is the iteration limits, and $n$ is the population size. ($nlog(n)$ because of the sort)\\
    Space Complexity: $O(l*n)$. \\
    This algorithm is not guaranteed to find an optimal solution because it's a local search algorithm that can only provide an approximately good solution.
    \item
    Run proteinFolding.py that is attached.
    The best conformation we got by this algorithm has a total cost of $271.3290352447519$, with acids placed in order in the following coordinates: (0, 0), (0, -1), (0, -2), (1, -2), (2, -2), (2, -1), (3, -1), (3, -2), (3, -3), (2, -3), (2, -4), (3, -4), (4, -4), (4, -5), (3, -5), (2, -5), (1, -5), (0, -5), (0, -4), (1, -4), (1, -3), (0, -3), (-1, -3), (-1, -4), (-1, -5), (-1, -6), (-2, -6), (-2, -5), (-2, -4), (-2, -3), (-2, -2), (-2, -1), (-2, 0), (-2, 1)\\
    \end{itemize}
    
    \begin{thebibliography}{9}
    \bibitem{protein}
    \textit{An effective hybrid of hill climbing and genetic algorithm for 2D triangular protein structure prediction}
    \end{thebibliography}
\end{onehalfspace}
\end{document}
