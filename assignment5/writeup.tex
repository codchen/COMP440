\documentclass[11pt]{article}
\usepackage[left=2cm,top=2cm,right=2cm,bottom=2cm]{geometry}
\usepackage{graphicx}
\usepackage{setspace}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage[]{algorithm2e}
\usepackage{amsmath}
\usepackage[noend]{algpseudocode}
\usepackage{float}
\title{COMP 440 Homework 5}
\author{Tony Chen(xc12) and Adam Wang(sw33)}
\date{October 2016}
\begin{document}
\begin{onehalfspace}
\maketitle{}
\section{Bayesian networks for astronomy}
\begin{itemize}
	\item
	Based on the above information, it can be seen that $M_1$ and $N$, $M_2$ and $N$, $F_1$ and $N$, $F_2$ and $N$ are pairs that conditionally dependent on each other. So the first network is incorrect since $F_1$ and $N$, $F_2$ and $N$ would become conditionally independent in that case. The second and the third network are correct.
	\item
	The second network is the best.\\
	Because it represents a more realistic conditional dependency: each measurement depends on both the true number of stars and whether the focus is bad. Consequently, the second network is also simpler than the third network.
	\item
	\begin{eqnarray*}
	P(M_1|N) &=& P(M_1|N,F_1)P(F_1|N)+P(M_1|N,\neg F_1)P(\neg F_1|N)\\
	&=& P(M_1|N,F_1)P(F_1) + P(M_1|N,\neg F_1)P(\neg F_1)
	\end{eqnarray*}
	\begin{center}
	  \begin{tabular}{l | c | c | r}
	  & $N = 1$ & $N = 2$ & $N = 3$\\ \hline
	  $M_1 = 0$ & $f + e(1 - f)$ & $f$ & $f$\\
	  $M_1 = 1$ & $(1-2e)(1-f)$ & $e(1-f)$ & $0$\\
	  $M_1 = 2$ & $e(1-f)$ & $(1-2e)(1-f)$ & $e(1-f)$\\
	  $M_1 = 3$ & $0$ & $e(1-f)$ & $(1-2e)(1-f)$\\
	  $M_1 = 4$ & $0$ & $0$ & $e(1-f)$
	  \end{tabular}
	\end{center}
	\item
	If we only consider the result $M_1 = 1$, then the possible numbers of $N$ are $\{0,1,2,\geq 4\}$.\\
	If we only consider the result $M_2 = 3$, then the possible numbers of $N$ are $\{2,3,4,\geq 6\}$.\\
	So the possible number of $N$ is $2$ or $4$ or any integer greater than or equal to $6$.
	\item
	We need to know that the event of a telescope having one-off measurement mistake is independent of that same telescope having a bad focus, and also that the two telescopes are independent of each other. The following analysis is made based on this independence assumption.\\
	The only combination of events that can let $N=2$ is when both telescopes had good focuses and $M_1$ counted one down while $M_2$ counted one up. So the probability of this happening is $(1-f)^2e^2$.\\
	The only combination of events that can let $N=4$ is when $M_1$ had a bad focus and $M_2$ had a good focus but got the one-off mistake. So the probability of this happening is $f(1-f)e$.\\
	When $N \geq 4$, both telescopes had bad focuses. So the probability of this happening is $f^2$.\\
	Given the statement that $e$ is small and $f$ is much smaller, it is safe to assume that $0.5 > e >> f$. So $(1-f)^2e^2$ is the largest probability, which makes the most likely number of stars $2$.
\end{itemize}
\section{Gibbs Sampling}
\begin{itemize}
	\item
	\begin{eqnarray*}
	  P(R=T,S=T,W=T) &=& P(R=T,S=T,W=T|C=T)P(C=T)+\\
	  &&P(R=T,S=T,W=T|C=F)P(C=F)\\
	  &=& P(W=T|R=T,S=T)P(S=T,R=T|C=T)P(C=T)+\\
	  &&P(W=T|R=T,S=T)P(S=T,R=T|C=F)P(C=F)\\
	  &=& P(W=T|R=T,S=T)P(S=T|C=T)P(R=T|C=T)P(C=T)+\\
	  &&P(W=T|R=T,S=T)P(S=T|C=F)P(R=T|C=F)P(C=F)\\
	  &=& 0.99*0.1*0.8*0.5+0.99*0.5*0.2*0.5\\
	  &=& 0.0891
	\end{eqnarray*}
	\begin{eqnarray*}
	  P(R=F,S=T,W=T) &=& P(R=F,S=T,W=T|C=T)P(C=T)+\\
	  &&P(R=F,S=T,W=T|C=F)P(C=F)\\
	  &=& P(W=T|R=F,S=T)P(S=T,R=F|C=T)P(C=T)+\\
	  &&P(W=T|R=F,S=T)P(S=T,R=F|C=F)P(C=F)\\
	  &=& P(W=T|R=F,S=T)P(S=T|C=T)P(R=F|C=T)P(C=T)+\\
	  &&P(W=T|R=F,S=T)P(S=T|C=F)P(R=F|C=F)P(C=F)\\
	  &=& 0.9*0.1*0.2*0.5+0.9*0.5*0.8*0.5\\
	  &=& 0.189
	\end{eqnarray*}
	\begin{eqnarray*}
	  P(R|S=T,W=T) &=& \frac{P(R=T,S=T,W=T)}{P(S=T,W=T)}\\
	  &=& \frac{P(R=T,S=T,W=T)}{P(R=T,S=T,W=T)+P(R=F,S=T,W=T)}\\
	  &=& \frac{0.0891}{0.0891+0.189}\\
	  &=& 0.3204
	\end{eqnarray*}
	\item
	\begin{itemize}
	  \item
	  There are four states: $\{(C=F,R=F),(C=F,R=T),(C=T,R=F),(C=T,R=T)\}$
	  \item
	  We have the following probabilities computed:\\
	  $P(C=F,S=T,W=T,R=F)=0.5*0.5*0.8*0.9=0.18$\\
	  $P(C=F,S=T,W=T,R=T)=0.5*0.5*0.2*0.99=0.0495$\\
	  $P(C=T,S=T,W=T,R=F)=0.5*0.1*0.2*0.9=0.009$\\
	  $P(C=T,S=T,W=T,R=T)=0.5*0.1*0.8*0.99=0.0396$\\
	  $P(C=F|S=T,W=T,R=F)=\frac{P(C=F,S=T,W=T,R=F)}{P(C=F,S=T,W=T,R=F)+P(C=T,S=T,W=T,R=F)}=0.9524$\\
	  $P(C=T|S=T,W=T,R=F)=\frac{P(C=T,S=T,W=T,R=F)}{P(C=F,S=T,W=T,R=F)+P(C=T,S=T,W=T,R=F)}=0.0476$\\
	  $P(C=F|S=T,W=T,R=T)=\frac{P(C=F,S=T,W=T,R=T)}{P(C=F,S=T,W=T,R=T)+P(C=T,S=T,W=T,R=T)}=0.5556$\\
	  $P(C=T|S=T,W=T,R=T)=\frac{P(C=T,S=T,W=T,R=T)}{P(C=F,S=T,W=T,R=T)+P(C=T,S=T,W=T,R=T)}=0.4444$\\
	  $P(R=F|S=T,W=T,C=F)=\frac{P(C=F,S=T,W=T,R=F)}{P(C=F,S=T,W=T,R=F)+P(C=F,S=T,W=T,R=T)}=0.7843$\\
	  $P(R=T|S=T,W=T,C=F)=\frac{P(C=F,S=T,W=T,R=T)}{P(C=F,S=T,W=T,R=F)+P(C=F,S=T,W=T,R=T)}=0.2157$\\
	  $P(R=F|S=T,W=T,C=T)=\frac{P(C=T,S=T,W=T,R=F)}{P(C=T,S=T,W=T,R=F)+P(C=T,S=T,W=T,R=T)}=0.1852$\\
	  $P(R=T|S=T,W=T,C=T)=\frac{P(C=T,S=T,W=T,R=T)}{P(C=T,S=T,W=T,R=F)+P(C=T,S=T,W=T,R=T)}=0.8148$\\
	  \begin{center}
	    \begin{tabular}{l | c | c | c | r}
	     & (C=F,R=F) & (C=F,R=T) & (C=T,R=F) & (C=T,R=T)\\ \hline
	     (C=F,R=F) & 0.8684 & 0.1078 & 0.0238 & 0\\
	     (C=F,R=T) & 0.3922 & 0.3856 & 0 & 0.2222\\
	     (C=T,R=F) & 0.4762 & 0 & 0.1164 & 0.4074\\
	     (C=T,R=T) & 0 & 0.2778 & 0.0926 & 0.6296\\
	    \end{tabular}
	  \end{center}
	  \item
	  $Q^n$ is the following matrix:\\
	  \begin{center}
	    \begin{tabular}{l | c | c | c | r}
	    & (C=F,R=F) & (C=F,R=T) & (C=T,R=F) & (C=T,R=T)\\ \hline
	     (C=F,R=F) & 0.64737659 &  0.17794021 &  0.03235323 &  0.14232997\\
	     (C=F,R=T) & 0.64737659 &  0.17794021 &  0.03235323 &  0.14232997\\
	     (C=T,R=F) & 0.64737659 &  0.17794021 &  0.03235323 &  0.14232997\\
	     (C=T,R=T) & 0.64737659 &  0.17794021 &  0.03235323 &  0.14232997\\
	    \end{tabular}
	  \end{center}
	  It can be seen that $Q(,C(C=F,R=T)) + Q(,C(C=T,R=T)) = 0.3203$, which is basically the same as the answer to part (a). This is as expected since these two columns combined represent $P(R=T|S=T,W=T)$.
	\item
	*The code used is appended in file p2.py.\\
	When $N=1000$, the probabilities of the four states are: $0.64737659,0.17794021,0.03235323,0.14232997$, which gives $P(R=T|S=T,W=T)=0.3203$.\\
	When $N=5000$, the probabilities of the four states are: $0.64737659,0.17794021,0.03235323,0.14232997$, which gives $P(R=T|S=T,W=T)=0.3203$.\\
	When $N=10000$, the probabilities of the four states are: $0.64737659,0.17794021,0.03235323,0.14232997$, which gives $P(R=T|S=T,W=T)=0.3203$.\\
	My guess for the burn-in period of this Markov chain is 100.
	\end{itemize}
\end{itemize}
\section{Tracking cars by particle filtering}
\section{Bayesian networks for predicting the 2016 presidential elections}
\end{onehalfspace}
\end{document}